{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498b9338-fe91-42e4-a766-71931a23264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7^1\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "\n",
    "def nt(n):\n",
    "    for i in range(2, int(sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return n > 1\n",
    "def phantic(n):\n",
    "    if nt(n):\n",
    "        print(n, \"^1\", sep = \"\")\n",
    "        return \n",
    "    for i in range(2, int(sqrt(n)) + 1, 1):\n",
    "        m = int(0)\n",
    "        while n % i == 0:\n",
    "            n //= i\n",
    "            m += 1\n",
    "        if  m != 0 and n > 1 :\n",
    "            print(i,'^',m, sep = \"\", end =  \" * \")\n",
    "        elif m != 0:\n",
    "            print(i,'^',m, sep = \"\", end =  \" \")\n",
    "    if n > 1:\n",
    "        print(\" \", n, \"^1\", sep = \"\" )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n = int(input())\n",
    "    phantic(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5f213b-b5a1-47be-a027-9e878b4822ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-545.00635, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6f0ec-4fd7-4e00-b45d-6507c8e6d9b9",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a6eda1-3063-4487-b524-cfa19bf5e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb6e2bed-087d-4acb-ad40-8674b880feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df567013-f8e0-446a-97f0-0ec126fc60ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7518875888650991979\n",
      "xla_global_id: -1\n",
      "\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Kiểm tra tất cả các thiết bị\n",
    "devices = device_lib.list_local_devices()\n",
    "for device in devices:\n",
    "    print(device)\n",
    "\n",
    "# Kiểm tra GPU có được phát hiện không\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caaad745-ff12-445b-b536-4869d01b7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuDNN enabled: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Kiểm tra xem cuDNN có được sử dụng không\n",
    "print(\"Is cuDNN enabled:\", tf.config.experimental.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f686039-0f0e-4d4e-a2ad-454e30267e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'is_cuda_build': False, 'is_rocm_build': False, 'is_tensorrt_build': False, 'msvcp_dll_names': 'msvcp140.dll,msvcp140_1.dll'})\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.sysconfig.get_build_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba72bfa-89fc-4bff-a7d2-2ff1a2f47fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu khai thác GPU trong 20 giây...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.14 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHoàn tất khai thác GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Thực thi khai thác GPU trong 20 giây\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mstress_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m, in \u001b[0;36mstress_gpu\u001b[1;34m(duration)\u001b[0m\n\u001b[0;32m     15\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m<\u001b[39m duration:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Tạo hai ma trận lớn ngẫu nhiên trên GPU\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     mat1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     mat2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m30000\u001b[39m, \u001b[38;5;241m30000\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Thực hiện phép nhân ma trận\u001b[39;00m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.14 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Kiểm tra xem GPU có khả dụng không\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"GPU không khả dụng. Hãy kiểm tra lại!\")\n",
    "    exit()\n",
    "\n",
    "# Đảm bảo PyTorch sử dụng GPU\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Hàm tạo tải liên tục trên GPU\n",
    "def stress_gpu(duration=10):\n",
    "    print(f\"Bắt đầu khai thác GPU trong {duration} giây...\")\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration:\n",
    "        # Tạo hai ma trận lớn ngẫu nhiên trên GPU\n",
    "        mat1 = torch.randn((30000, 30000), device=device)\n",
    "        mat2 = torch.randn((30000, 30000), device=device)\n",
    "        \n",
    "        # Thực hiện phép nhân ma trận\n",
    "        result = torch.matmul(mat1, mat2)\n",
    "        \n",
    "        # Tính tổng kết quả để giữ GPU bận\n",
    "        total_sum = result.sum()\n",
    "        \n",
    "        # Giải phóng bộ nhớ tạm thời (nếu cần)\n",
    "        del mat1, mat2, result, total_sum\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"Hoàn tất khai thác GPU.\")\n",
    "\n",
    "# Thực thi khai thác GPU trong 20 giây\n",
    "stress_gpu(duration=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a645b-eefc-42f9-8518-bcf4f3465ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
